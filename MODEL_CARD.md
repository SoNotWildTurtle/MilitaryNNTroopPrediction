# Model Card

## Overview
This project detects and tracks military assets in satellite and drone imagery.
YOLO-based detectors and a trajectory model estimate positions and movement trends
for troops, vehicles, and drones.

## Data
- **Satellite imagery**: Public Sentinel tiles and optional classified sources.
- **Drone footage**: Live feeds captured via `drones/live_feed.py`.
- **Synthetic data**: Shapes generated by `utils/demo_dataset.py` for offline tests.
- **OSINT**: Movement reports ingested into MongoDB.

## Evaluation
- Detection confidence is calibrated with human feedback via isotonic regression.
- `analysis/confidence_stats.py` highlights weak classes.
- Trajectory predictions are validated against recent movement logs.

## Intended Use
Support defensive analysis for the Ukrainian military and government.
Outputs should inform situational awareness, not autonomous targeting.

## Limitations
- Models are trained on limited open-source data and may miss novel tactics.
- Sentinel imagery can be obstructed by weather or outdated tiles.
- Live video streams require stable network connections.

Use with human oversight and respect for operational policy.
